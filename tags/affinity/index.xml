<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Affinity - 标签 - 蜷缩的蜗牛</title><link>https://www.kbsonlong.com/tags/affinity/</link><description>云原生时代运维</description><generator>Hugo 0.145.0 &amp; FixIt v0.3.20</generator><language>zh-CN</language><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Thu, 08 Mar 2018 00:00:00 +0000</lastBuildDate><atom:link href="https://www.kbsonlong.com/tags/affinity/index.xml" rel="self" type="application/rss+xml"/><item><title>理解 Kubernetes 的亲和性调度</title><link>https://www.kbsonlong.com/posts/understand-the-affinity-scheduling-of-kubernetes/</link><pubDate>Thu, 08 Mar 2018 00:00:00 +0000</pubDate><guid>https://www.kbsonlong.com/posts/understand-the-affinity-scheduling-of-kubernetes/</guid><description>&lt;p>一般情况下我们部署的 POD 是通过集群自动调度选择某个节点的，默认情况下调度器考虑的是资源足够，并且负载尽量平均，但是有的时候我们需要能够更加细粒度的去控制 POD 的调度，比如我们内部的一些服务 gitlab 之类的也是跑在&lt;code>Kubernetes&lt;/code>集群上的，我们就不希望对外的一些服务和内部的服务跑在同一个节点上了，害怕内部服务对外部的服务产生影响；有的时候呢我们两个服务直接交流比较频繁，又希望能够将这两个服务的 POD 调度到同样的节点上。这就需要用到 Kubernetes 里面的一个概念：亲和性，亲和性主要分为两类：&lt;code>nodeAffinity&lt;/code>和&lt;code>podAffinity&lt;/code>。&lt;/p></description></item></channel></rss>